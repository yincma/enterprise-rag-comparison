# ç³»ç»Ÿä¸€ï¼šé›¶æˆæœ¬æœ¬åœ°åŒ–RAGçŸ¥è¯†é—®ç­”ç³»ç»Ÿ

## ğŸ¯ ç³»ç»Ÿæ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªå®Œå…¨æœ¬åœ°åŒ–çš„RAGï¼ˆRetrieval-Augmented Generationï¼‰çŸ¥è¯†é—®ç­”ç³»ç»Ÿï¼Œæ—¨åœ¨æä¾›é›¶äº‘ç«¯è´¹ç”¨ã€ä¿æŠ¤ä¼ä¸šæ•°æ®éšç§çš„è§£å†³æ–¹æ¡ˆã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ†“ **é›¶æˆæœ¬è¿è¡Œ**ï¼šæ— äº‘æœåŠ¡è´¹ç”¨ï¼Œä»…éœ€æœ¬åœ°ç¡¬ä»¶
- ğŸ”’ **æ•°æ®éšç§**ï¼šæ–‡æ¡£å’ŒæŸ¥è¯¢å®Œå…¨æœ¬åœ°å¤„ç†ï¼Œä¸ä¸Šä¼ äº‘ç«¯
- âš¡ **å¿«é€Ÿå“åº”**ï¼šæœ¬åœ°æ¨ç†ï¼Œæ— ç½‘ç»œå»¶è¿Ÿ
- ğŸ“š **å¤šæ ¼å¼æ”¯æŒ**ï¼šPDFã€Wordã€Markdownã€TXTç­‰
- ğŸ¨ **å‹å¥½ç•Œé¢**ï¼šåŸºäºStreamlitçš„ç›´è§‚Webç•Œé¢
- ğŸ”§ **æ˜“äºéƒ¨ç½²**ï¼šä¸€é”®å®‰è£…ï¼Œå¼€ç®±å³ç”¨

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

```mermaid
graph TD
    A[ä¼ä¸šæ–‡æ¡£] --> B[æ–‡æ¡£å¤„ç†å™¨]
    B --> C[æ–‡æœ¬åˆ†å—]
    C --> D[å‘é‡åµŒå…¥]
    D --> E[ChromaDBå­˜å‚¨]
    
    F[ç”¨æˆ·æŸ¥è¯¢] --> G[Streamlitç•Œé¢]
    G --> H[æŸ¥è¯¢å¤„ç†]
    H --> I[å‘é‡æ£€ç´¢]
    E --> I
    I --> J[ä¸Šä¸‹æ–‡æ„å»º]
    J --> K[Ollama LLM]
    K --> L[ç­”æ¡ˆç”Ÿæˆ]
    L --> G
```

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | ç‰ˆæœ¬ | ä½œç”¨ |
|------|---------|------|------|
| **LLM** | Ollama + Llama3.1 | Latest | æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹æ¨ç† |
| **å‘é‡æ•°æ®åº“** | ChromaDB | 0.4.0+ | æ–‡æ¡£å‘é‡å­˜å‚¨å’Œæ£€ç´¢ |
| **åµŒå…¥æ¨¡å‹** | sentence-transformers | Latest | æ–‡æœ¬å‘é‡åŒ– |
| **å‰ç«¯æ¡†æ¶** | Streamlit | 1.28.0+ | Webç”¨æˆ·ç•Œé¢ |
| **æ–‡æ¡£å¤„ç†** | PyPDF2, python-docx | Latest | å¤šæ ¼å¼æ–‡æ¡£è§£æ |
| **RAGæ¡†æ¶** | LangChain | 0.1.0+ | æ£€ç´¢å¢å¼ºç”Ÿæˆæµç¨‹ |

## ğŸ“ é¡¹ç›®ç»“æ„

```
system-1-local-free/
â”œâ”€â”€ README.md                    # æœ¬æ–‡ä»¶
â”œâ”€â”€ requirements.txt             # Pythonä¾èµ–
â”œâ”€â”€ src/                         # æ ¸å¿ƒæºç 
â”‚   â”œâ”€â”€ main.py                 # Streamlitä¸»åº”ç”¨
â”‚   â”œâ”€â”€ document_processor.py   # æ–‡æ¡£å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ vector_store.py        # ChromaDBå‘é‡å­˜å‚¨
â”‚   â”œâ”€â”€ llm_manager.py         # Ollama LLMç®¡ç†
â”‚   â”œâ”€â”€ rag_pipeline.py        # RAGä¸»æµç¨‹
â”‚   â””â”€â”€ utils/                 # å·¥å…·æ¨¡å—
â”‚       â”œâ”€â”€ config.py          # é…ç½®ç®¡ç†
â”‚       â””â”€â”€ helpers.py         # è¾…åŠ©å‡½æ•°
â”œâ”€â”€ config/                     # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ app_config.yaml        # åº”ç”¨é…ç½®
â”‚   â””â”€â”€ model_config.yaml      # æ¨¡å‹é…ç½®
â”œâ”€â”€ data/                      # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ documents/             # ä¸Šä¼ æ–‡æ¡£
â”‚   â””â”€â”€ vector_db/            # å‘é‡æ•°æ®åº“å­˜å‚¨
â”œâ”€â”€ tests/                     # æµ‹è¯•ä»£ç 
â”œâ”€â”€ docs/                      # æ–‡æ¡£
â””â”€â”€ logs/                      # æ—¥å¿—æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# ç¡®ä¿Pythonç‰ˆæœ¬ >= 3.8
python --version

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–è€… venv\Scripts\activate  # Windows
```

### 2. å®‰è£…ä¾èµ–

```bash
cd system-1-local-free
pip install -r requirements.txt
```

### 3. å®‰è£…Ollama

```bash
# Mac
brew install ollama

# Linux
curl -fsSL https://ollama.com/install.sh | sh

# å¯åŠ¨OllamaæœåŠ¡
ollama serve

# ä¸‹è½½Llama3.1æ¨¡å‹
ollama pull llama3.1:8b
```

### 4. å¯åŠ¨ç³»ç»Ÿ

```bash
streamlit run src/main.py
```

ç³»ç»Ÿå°†åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼Œé»˜è®¤åœ°å€ï¼š`http://localhost:8501`

## ğŸ’¡ ä½¿ç”¨æŒ‡å—

### æ–‡æ¡£ä¸Šä¼ 
1. ç‚¹å‡»ä¾§è¾¹æ çš„"ä¸Šä¼ æ–‡æ¡£"æŒ‰é’®
2. é€‰æ‹©PDFã€Wordæˆ–Markdownæ–‡ä»¶
3. ç³»ç»Ÿè‡ªåŠ¨å¤„ç†å¹¶å»ºç«‹å‘é‡ç´¢å¼•

### çŸ¥è¯†é—®ç­”
1. åœ¨ä¸»ç•Œé¢è¾“å…¥é—®é¢˜
2. ç³»ç»Ÿæ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ
3. åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆå‡†ç¡®ç­”æ¡ˆ

### é«˜çº§åŠŸèƒ½
- **æ‰¹é‡ä¸Šä¼ **ï¼šä¸€æ¬¡ä¸Šä¼ å¤šä¸ªæ–‡æ¡£
- **æ–‡æ¡£ç®¡ç†**ï¼šæŸ¥çœ‹ã€åˆ é™¤å·²ä¸Šä¼ æ–‡æ¡£
- **æ£€ç´¢è°ƒè¯•**ï¼šæŸ¥çœ‹æ£€ç´¢åˆ°çš„ç›¸å…³ç‰‡æ®µ
- **å¯¹è¯å†å²**ï¼šä¿å­˜é—®ç­”è®°å½•

## ğŸ”§ é…ç½®è¯´æ˜

### åº”ç”¨é…ç½® (`config/app_config.yaml`)
```yaml
app:
  name: "ä¼ä¸šRAGçŸ¥è¯†é—®ç­”ç³»ç»Ÿ"
  version: "1.0.0"
  debug: false

vector_store:
  chunk_size: 500
  chunk_overlap: 50
  collection_name: "enterprise_docs"

retrieval:
  top_k: 5
  similarity_threshold: 0.7
```

### æ¨¡å‹é…ç½® (`config/model_config.yaml`)
```yaml
llm:
  model_name: "llama3.1:8b"
  temperature: 0.1
  max_tokens: 1000

embedding:
  model_name: "all-MiniLM-L6-v2"
  dimension: 384
```

## ğŸ“Š æ€§èƒ½å‚æ•°

| æŒ‡æ ‡ | è§„æ ¼ |
|------|------|
| **å“åº”æ—¶é—´** | < 3ç§’ï¼ˆæœ¬åœ°æ¨ç†ï¼‰ |
| **æ–‡æ¡£å®¹é‡** | æ— é™åˆ¶ï¼ˆå—æœ¬åœ°å­˜å‚¨é™åˆ¶ï¼‰ |
| **æ”¯æŒè¯­è¨€** | ä¸­æ–‡ã€è‹±æ–‡ |
| **å¹¶å‘ç”¨æˆ·** | 1-10äººï¼ˆå—ç¡¬ä»¶é™åˆ¶ï¼‰ |
| **å†…å­˜éœ€æ±‚** | 8GB+ æ¨è |
| **å­˜å‚¨éœ€æ±‚** | 10GB+ï¼ˆå«æ¨¡å‹æ–‡ä»¶ï¼‰ |

## ğŸ” ç³»ç»Ÿç›‘æ§

### æ€§èƒ½ç›‘æ§
- CPUå’Œå†…å­˜ä½¿ç”¨ç‡
- å“åº”æ—¶é—´ç»Ÿè®¡
- æŸ¥è¯¢æˆåŠŸç‡

### æ—¥å¿—ç®¡ç†
```
logs/
â”œâ”€â”€ app.log          # åº”ç”¨æ—¥å¿—
â”œâ”€â”€ error.log        # é”™è¯¯æ—¥å¿—
â””â”€â”€ performance.log  # æ€§èƒ½æ—¥å¿—
```

## ğŸ›¡ï¸ å®‰å…¨ç‰¹æ€§

- **æ•°æ®æœ¬åœ°åŒ–**ï¼šæ‰€æœ‰æ•°æ®å¤„ç†åœ¨æœ¬åœ°è¿›è¡Œ
- **æ— ç½‘ç»œä¾èµ–**ï¼šç¦»çº¿ä¹Ÿå¯æ­£å¸¸å·¥ä½œ
- **è®¿é—®æ§åˆ¶**ï¼šå¯é…ç½®ç”¨æˆ·è®¤è¯
- **æ—¥å¿—å®¡è®¡**ï¼šè¯¦ç»†æ“ä½œè®°å½•

## ğŸ”„ å‡çº§æŒ‡å—

### æ¨¡å‹å‡çº§
```bash
# ä¸‹è½½æ›´æ–°çš„æ¨¡å‹
ollama pull llama3.1:70b  # æ›´å¤§æ›´å¼ºçš„æ¨¡å‹

# ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹åç§°
```

### åŠŸèƒ½æ‰©å±•
- æ·»åŠ æ›´å¤šæ–‡æ¡£æ ¼å¼æ”¯æŒ
- é›†æˆæ›´å¤šå¼€æºLLM
- å¢å¼ºç”¨æˆ·ç•Œé¢åŠŸèƒ½

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **OllamaæœåŠ¡æ— æ³•å¯åŠ¨**
   ```bash
   # æ£€æŸ¥æœåŠ¡çŠ¶æ€
   ollama serve
   ```

2. **å‘é‡æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥**
   ```bash
   # æ¸…ç©ºæ•°æ®åº“é‡æ–°åˆå§‹åŒ–
   rm -rf data/vector_db/
   ```

3. **å†…å­˜ä¸è¶³**
   - ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚llama3.1:7bï¼‰
   - è°ƒæ•´chunk_sizeå‚æ•°

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### ç¡¬ä»¶å»ºè®®
- **CPU**: 8æ ¸å¿ƒä»¥ä¸Š
- **å†…å­˜**: 16GB+
- **å­˜å‚¨**: SSDæ¨è
- **GPU**: å¯é€‰ï¼ŒåŠ é€Ÿæ¨ç†

### è½¯ä»¶ä¼˜åŒ–
- å¯ç”¨æ–‡æ¡£ç¼“å­˜
- è°ƒä¼˜æ£€ç´¢å‚æ•°
- ä½¿ç”¨æ›´é«˜æ•ˆçš„åµŒå…¥æ¨¡å‹

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Forkæœ¬é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤ä»£ç æ›´æ”¹
4. åˆ›å»ºPull Request

## ğŸ“„ å¼€æºåè®®

MIT License

---

**å¼€å‘å›¢é˜Ÿ**ï¼šä¼ä¸šRAGç ”å‘å°ç»„  
**æœ€åæ›´æ–°**ï¼š2025å¹´1æœˆ21æ—¥  
**ç³»ç»Ÿç‰ˆæœ¬**ï¼šv1.0.0